<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=240, height=282, initial-scale=1.0">
    <title>Rabbit R1 Camera Rotation & Mic Test</title>
    <style>
        body {
            margin: 0;
            padding: 10px;
            font-family: Arial, sans-serif;
            font-size: 12px;
            width: 240px;
            height: 282px;
            overflow-y: auto;
            background-color: #f0f0f0;
            box-sizing: border-box;
        }
        h1 {
            font-size: 16px;
            margin-bottom: 10px;
        }
        section {
            margin-bottom: 15px;
            border-bottom: 1px solid #ccc;
            padding-bottom: 10px;
        }
        button {
            min-width: 44px;
            min-height: 44px;
            margin: 5px 0;
            padding: 8px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        #camera-preview {
            width: 100%;
            height: auto;
            max-height: 200px;
        }
        #mic-canvas {
            width: 100%;
            height: 50px;
            background-color: #fff;
            border: 1px solid #ddd;
        }
        .log-div {
            background-color: #fff;
            border: 1px solid #ddd;
            padding: 10px;
            height: 100px;
            overflow-y: auto;
            font-size: 10px;
            white-space: pre-wrap;
        }
        p {
            margin: 5px 0;
        }
    </style>
</head>
<body>
    <h1>R1 Camera Rotation & Mic Tester</h1>
    
    <section id="camera">
        <h2>Camera Test (with Rotation)</h2>
        <p>Note: Use the scroll wheel to rotate the camera and observe if the preview updates. Enter vision mode by double-pressing the side button if needed.</p>
        <button id="start-camera">Start Camera Preview</button>
        <button id="capture-photo">Capture Photo</button>
        <button id="stop-camera">Stop Camera</button>
        <video id="camera-preview" autoplay playsinline></video>
        <div id="camera-log" class="log-div"></div>
    </section>
    
    <section id="mic">
        <h2>Mic Test</h2>
        <button id="start-mic">Start Mic (Visualize Levels)</button>
        <button id="stop-mic">Stop Mic</button>
        <canvas id="mic-canvas"></canvas>
        <div id="mic-log" class="log-div"></div>
    </section>

    <section id="global-log">
        <h2>Global Log</h2>
        <div id="log" class="log-div"></div>
    </section>

    <script>
        function log(message, targetId = 'log') {
            const target = document.getElementById(targetId);
            target.innerHTML += `${new Date().toISOString()}: ${message}\n`;
            target.scrollTop = target.scrollHeight;
        }

        // Camera Test
        let cameraStream = null;
        const videoElement = document.getElementById('camera-preview');

        async function startCamera() {
            try {
                cameraStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } }); // Try 'environment' first; user can rotate
                videoElement.srcObject = cameraStream;
                videoElement.play();
                log('Camera preview started (try rotating with scroll wheel)', 'camera-log');
                log('Camera preview started');
            } catch (e) {
                log(`Camera access error: ${e.message}`, 'camera-log');
                log(`Camera access error: ${e.message}`);
            }
        }

        function stopCamera() {
            if (cameraStream) {
                cameraStream.getTracks().forEach(track => track.stop());
                videoElement.srcObject = null;
                log('Camera stopped', 'camera-log');
                log('Camera stopped');
            }
        }

        async function capturePhoto() {
            if (!cameraStream) return log('Start camera first', 'camera-log');

            try {
                const canvas = document.createElement('canvas');
                canvas.width = 240;
                canvas.height = 282;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(videoElement, 0, 0, 240, 282);
                const base64Image = canvas.toDataURL('image/jpeg');
                log(`Photo captured: ${base64Image.substring(0, 50)}... (truncated)`, 'camera-log');
                log('Photo captured');
            } catch (e) {
                log(`Capture error: ${e.message}`, 'camera-log');
            }
        }

        document.getElementById('start-camera').addEventListener('click', startCamera);
        document.getElementById('stop-camera').addEventListener('click', stopCamera);
        document.getElementById('capture-photo').addEventListener('click', capturePhoto);

        // Mic Test
        let micStream = null;
        let audioContext = null;
        let analyser = null;
        let animationFrame = null;

        async function startMic() {
            try {
                micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(micStream);
                analyser = audioContext.createAnalyser();
                source.connect(analyser);
                analyser.fftSize = 256;
                log('Mic started - speaking to see levels', 'mic-log');
                log('Mic started');
                visualizeMic();
            } catch (e) {
                log(`Mic access error: ${e.message}`, 'mic-log');
                log(`Mic access error: ${e.message}`);
            }
        }

        function stopMic() {
            if (micStream) {
                micStream.getTracks().forEach(track => track.stop());
                if (audioContext) audioContext.close();
                cancelAnimationFrame(animationFrame);
                const canvas = document.getElementById('mic-canvas');
                const ctx = canvas.getContext('2d');
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                log('Mic stopped', 'mic-log');
                log('Mic stopped');
            }
        }

        function visualizeMic() {
            const canvas = document.getElementById('mic-canvas');
            const ctx = canvas.getContext('2d');
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);

            function draw() {
                animationFrame = requestAnimationFrame(draw);
                analyser.getByteFrequencyData(dataArray);
                ctx.fillStyle = '#f0f0f0';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                const barWidth = (canvas.width / bufferLength) * 2.5;
                let x = 0;
                for (let i = 0; i < bufferLength; i++) {
                    const barHeight = (dataArray[i] / 2);
                    ctx.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;
                    ctx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2);
                    x += barWidth + 1;
                }
            }
            draw();
        }

        document.getElementById('start-mic').addEventListener('click', startMic);
        document.getElementById('stop-mic').addEventListener('click', stopMic);

        log('Camera Rotation & Mic Test initialized');
    </script>
</body>
</html>
